ğŸŸ¥ Stop K3s
bash
Copy
Edit
sudo systemctl stop k3s
ğŸŸ© Start K3s
bash
Copy
Edit
sudo systemctl start k3s
ğŸ” Restart K3s
bash
Copy
Edit
sudo systemctl restart k3s
ğŸ“‹ Check Status
bash
Copy
Edit
sudo systemctl status k3s

ğŸ”§ 1. Install NVIDIA Drivers (if not already installed)
Check with:

bash
Copy
Edit
nvidia-smi
If it returns GPU info, youâ€™re good. If not:

bash
Copy
Edit
sudo apt update
sudo apt install -y nvidia-driver-535
sudo reboot
ğŸ”§ 2. Install NVIDIA Container Toolkit
This enables Docker (and containerd) to run GPU workloads.

bash
Copy
Edit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID) && \
curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo apt-key add - && \
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

sudo apt update
sudo apt install -y nvidia-container-toolkit
ğŸ”§ 3. Configure containerd (used by K3s) to support NVIDIA runtime
Create or edit the file:

bash
Copy
Edit
sudo nano /etc/rancher/k3s/registries.yaml
Add:

yaml
Copy
Edit
configs:
  default:
    containerd:
      default_runtime_name: nvidia
      runtimes:
        nvidia:
          runtime_type: io.containerd.runc.v2
          options:
            BinaryName: "nvidia-container-runtime"
ğŸ”„ 4. Restart K3s
Now that the runtime is in place, restart K3s:

bash
Copy
Edit
sudo systemctl restart k3s
Then check:

bash
Copy
Edit
sudo systemctl status k3s
You should see it running successfully.

ğŸ§ª Optional: Verify NVIDIA Runtime in a Pod
Create a simple pod spec to use GPU:

yaml
Copy
Edit
apiVersion: v1
kind: Pod
metadata:
  name: gpu-test
spec:
  containers:
  - name: cuda-container
    image: nvidia/cuda:11.0-base
    command: ["nvidia-smi"]
    resources:
      limits:
        nvidia.com/gpu: 1
Apply it:

bash
Copy
Edit
kubectl apply -f gpu-test.yaml
kubectl logs gpu-test






https://docs.lambdalabs.com/education/large-language-models/k8s-ollama-llama-3-2/
https://gist.github.com/clemenko/e3a823732c23813b43ac18fef0b24498


curl -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-container-runtime/ubuntu22.04/nvidia-container-runtime.list |  sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list

wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
sudo dpkg -i cuda-keyring_1.0-1_all.deb

sudo apt update
sudo apt install -y  nvidia-container-runtime

nvidia-container-cli info
nvidia-smi


curl -sfL https://get.k3s.io | K3S_KUBECONFIG_MODE=644 sh -s - --default-runtime=nvidia --disable traefik



# Copy k3s config to your home directory
sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
sudo chown $USER:$USER ~/.kube/config
chmod 600 ~/.kube/config

export KUBECONFIG=~/.kube/config

sudo systemctl status k3s

curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 \
    && chmod 700 get_helm.sh \
    && ./get_helm.sh

kubectl create ns gpu-operator
kubectl label --overwrite ns gpu-operator pod-security.kubernetes.io/enforce=privileged

kubectl get nodes -o json | jq '.items[].metadata.labels | keys | any(startswith("feature.node.kubernetes.io"))'

helm repo add nvidia https://helm.ngc.nvidia.com/nvidia \
    && helm repo update

helm install --wait --generate-name \
    -n gpu-operator --create-namespace \
    nvidia/gpu-operator \
    --version=v24.9.2

